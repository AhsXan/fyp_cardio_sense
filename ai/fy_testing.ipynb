{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62df24e-0d7f-4ee4-8591-23e161eaa40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, LSTM,\n",
    "    Dense, Dropout, BatchNormalization, GlobalAveragePooling1D, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import resample\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "FS_TARGET = 2000      # Sampling rate\n",
    "DURATION = 3.0        # seconds\n",
    "ANALOG_LEN = 250      # CNN input length\n",
    "MFCC_LEN = 38         # LSTM input time steps\n",
    "N_MFCC = 20           # Number of MFCC coefficients\n",
    "\n",
    "DATA_DIR = r\"E:\\Final Year Project\\Data Training\"  # Change to your processed data folder\n",
    "\n",
    "# ================= LOAD RAW WAV FILES AND PREPROCESS =================\n",
    "def preprocess_file(file_path):\n",
    "    # Load audio\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    if sr != FS_TARGET:\n",
    "        audio = librosa.resample(audio, sr, FS_TARGET)\n",
    "    max_len = int(FS_TARGET * DURATION)\n",
    "    audio = audio[:max_len] if len(audio) > max_len else np.pad(audio, (0, max_len - len(audio)))\n",
    "\n",
    "    # ---- Analog (CNN) ----\n",
    "    b, a = signal.butter(4, [20/(FS_TARGET/2), 400/(FS_TARGET/2)], btype='band')\n",
    "    analog = signal.filtfilt(b, a, audio)\n",
    "    analog = resample(analog, ANALOG_LEN).reshape(ANALOG_LEN,1)\n",
    "\n",
    "    # ---- MFCC (LSTM) ----\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=FS_TARGET, n_mfcc=N_MFCC).T\n",
    "    if mfcc.shape[0] > MFCC_LEN:\n",
    "        mfcc = mfcc[:MFCC_LEN]\n",
    "    elif mfcc.shape[0] < MFCC_LEN:\n",
    "        mfcc = np.pad(mfcc, ((0, MFCC_LEN - mfcc.shape[0]), (0,0)))\n",
    "    \n",
    "    return analog, mfcc\n",
    "\n",
    "# ================= LOAD ALL DATA =================\n",
    "X_analog_list = []\n",
    "X_mfcc_list = []\n",
    "y_list = []\n",
    "\n",
    "for label_folder in os.listdir(DATA_DIR):\n",
    "    label_path = os.path.join(DATA_DIR, label_folder)\n",
    "    if os.path.isdir(label_path):\n",
    "        label_index = 0 if label_folder.lower() == \"normal\" else 1\n",
    "        for file_name in os.listdir(label_path):\n",
    "            if file_name.lower().endswith(\".wav\"):\n",
    "                file_path = os.path.join(label_path, file_name)\n",
    "                analog, mfcc = preprocess_file(file_path)\n",
    "                X_analog_list.append(analog)\n",
    "                X_mfcc_list.append(mfcc)\n",
    "                y_list.append(label_index)\n",
    "\n",
    "X_analog = np.array(X_analog_list)\n",
    "X_mfcc = np.array(X_mfcc_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_cat = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Train-test split\n",
    "Xa_tr, Xa_te, Xd_tr, Xd_te, y_tr, y_te = train_test_split(\n",
    "    X_analog, X_mfcc, y_cat,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ================= BUILD HYBRID MODEL =================\n",
    "# CNN Branch\n",
    "analog_input = Input(shape=(ANALOG_LEN,1))\n",
    "x = Conv1D(64,5,activation='relu',padding='same')(analog_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(128,3,activation='relu',padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# LSTM Branch\n",
    "digital_input = Input(shape=(MFCC_LEN,N_MFCC))\n",
    "y_l = LSTM(64)(digital_input)\n",
    "y_l = Dense(64,activation='relu')(y_l)\n",
    "y_l = BatchNormalization()(y_l)\n",
    "\n",
    "# Fusion\n",
    "combined = Concatenate()([x,y_l])\n",
    "z = Dense(64,activation='relu')(combined)\n",
    "z = Dropout(0.4)(z)\n",
    "output = Dense(2,activation='softmax')(z)\n",
    "\n",
    "model = Model([analog_input,digital_input],output)\n",
    "\n",
    "# ================= COMPILE =================\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ================= TRAIN =================\n",
    "history = model.fit(\n",
    "    [Xa_tr, Xd_tr], y_tr,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=5, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ================= EVALUATE =================\n",
    "pred = model.predict([Xa_te, Xd_te])\n",
    "pred_cls = np.argmax(pred, axis=1)\n",
    "true_cls = np.argmax(y_te, axis=1)\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(true_cls, pred_cls))\n",
    "\n",
    "# ================= SAVE MODEL =================\n",
    "model.save(\"hybrid_cnn_lstm_heart_sound_final.h5\")\n",
    "print(\"\\nâœ… Hybrid CNN+LSTM model trained and saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
